{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d65ceb",
   "metadata": {},
   "source": [
    "# Installing Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ba9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/cb/cc/684ac2410ad06957c17ffda787b7ff6c1595721c36c3b443c021e95cf998/langchain-0.1.11-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\gorav sen\\python\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (1.4.51)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/91/ca/7219b838086086972e662c19e908694bdc6744537fb41b70392501b8b5e4/dataclasses_json-0.6.4-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.25 from https://files.pythonhosted.org/packages/b6/23/ceba35a18190531e3f13d12a71480efe0744a0b8420e3ea570b69ba2f381/langchain_community-0.0.25-py3-none-any.whl.metadata\n",
      "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1.29 from https://files.pythonhosted.org/packages/7e/e6/f3b22fc973610466b0b6cc2c15a65a4b706bc687975bbd96ddeb800bb54b/langchain_core-0.1.29-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.1,>=0.0.1 from https://files.pythonhosted.org/packages/9d/a1/aec824080111e9b4a4802b51b988032faa193828c865e11233d1b18e88fa/langchain_text_splitters-0.0.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.17 from https://files.pythonhosted.org/packages/c7/44/36ec55ac7b803d5dcea6d643b31d124577fff80832b01aa611fa2a18c7c8/langsmith-0.1.19-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (1.23.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from openai) (3.6.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gorav sen\\python\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\gorav sen\\python\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\gorav sen\\python\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gorav sen\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gorav sen\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gorav sen\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gorav sen\\python\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/38/04/37055b7013dfaaf66e3a9a51e46857cc9be151476a891b995fa70da7e139/marshmallow-3.21.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\gorav sen\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.6.15.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gorav sen\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gorav sen\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.29->langchain)\n",
      "  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/8f/6f/c6654219ad867ecebf85efbde6f6190634e9a6072246e63e2f7b60a1d717/orjson-3.9.15-cp310-none-win_amd64.whl.metadata\n",
      "  Downloading orjson-3.9.15-cp310-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 50.7/50.7 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\gorav sen\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\gorav sen\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gorav sen\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gorav sen\\python\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.12)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\gorav sen\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gorav sen\\python\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for mypy-extensions>=0.3.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
      "   ---------------------------------------- 807.5/807.5 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 1.8/1.8 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
      "   ---------------------------------------- 252.6/252.6 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.19-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 65.7/65.7 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 49.4/49.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading orjson-3.9.15-cp310-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 136.0/136.0 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 53.0/53.0 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.25 langchain-core-0.1.29 langchain-text-splitters-0.0.1 langsmith-0.1.19 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3224f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'INSERT-YOUR-OPENAI-KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72443fba",
   "metadata": {},
   "source": [
    "##### temporary fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## %pip install -U openAI==0.28.1\n",
    "# you may find some compatibility issue between default openAI and langchain\n",
    "# you may want to depracate openAI to 0.28.1 version using above command\n",
    "# Check the version using the following code, remove # and run\n",
    "# import openai\n",
    "# openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3e1f9",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197c797a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI am an AI and do not have the capability to feel emotions. But thank you for asking! Is there something I can assist you with?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# llm = OpenAI()\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct')\n",
    "llm.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df87ec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program, so I don't have feelings in the way that humans do. But I'm here and ready to assist you with any questions or tasks you have! How can I help you today?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "chat_model.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a933941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"What is the capital of Australia?\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict('What was my previous question?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be clearly seen that the model was unable to memorise what I asked previously. So it provided ambigious answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd4b75",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21009f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! I've been processing a lot of information and learning new things today. How about you?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('How are you today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693ec706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you today?\n",
      "AI: I'm doing well, thank you for asking! I've been processing a lot of information and learning new things today. How about you?\n",
      "Human: What was my previous question?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"How are you today?\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('What was my previous question?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now see using chains It was able to adapt to the new data(pevious question that I asked.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b00466",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27380e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain provides templates to generate prompts which are provided to model to generate better responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763a7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['category'], template='\\nReturn all the subcategories of the following category\\n\\n{category}\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Return all the subcategories of the following category\n",
    "\n",
    "{category}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['category'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd070513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return all the subcategories of the following category\n",
      "\n",
      "Machine Learning\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Decision Trees\\n- Support Vector Machines\\n- Neural Networks\\n- Clustering\\n- Classification\\n- Regression\\n- Ensemble Methods\\n- Dimensionality Reduction\\n- Anomaly Detection'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a07acc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\nYou are a helpful assistant who generate comma separated lists.\\nA user will only pass a category and you should generate subcategories of that category in a comma separated list.\\nONLY return comma separated and nothing more!\\n'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a helpful assistant who generate comma separated lists.\n",
    "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
    "ONLY return comma separated and nothing more!\n",
    "\"\"\"\n",
    "\n",
    "human_template = '{category}'\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    system_template\n",
    ")\n",
    "system_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a03819ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['category'], template='{category}'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    human_template\n",
    ")\n",
    "\n",
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce86e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Computer Science\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Algorithms, Artificial Intelligence, Data Structures, Databases, Machine Learning, Networking, Operating Systems, Programming Languages, Software Engineering'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message, human_message   \n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "chain.run('Computer Science')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fe368",
   "metadata": {},
   "source": [
    "# Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b56d7eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Supervised Learning',\n",
       " 'Unsupervised Learning',\n",
       " 'Reinforcement Learning',\n",
       " 'Deep Learning',\n",
       " 'Natural Language Processing',\n",
       " 'Computer Vision',\n",
       " 'Clustering',\n",
       " 'Classification',\n",
       " 'Regression',\n",
       " 'Dimensionality Reduction']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        output = text.strip().split(',')\n",
    "        output = [o.strip() for o in output]\n",
    "        return output\n",
    "    \n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    output_parser=CommaSeparatedParser(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee909622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.11'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aa0f8d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: food\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: country\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: colors\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': ['fruits',\n",
       "   'vegetables',\n",
       "   'grains',\n",
       "   'dairy',\n",
       "   'meat',\n",
       "   'seafood',\n",
       "   'snacks',\n",
       "   'desserts']},\n",
       " {'text': ['North America',\n",
       "   'South America',\n",
       "   'Europe',\n",
       "   'Asia',\n",
       "   'Africa',\n",
       "   'Oceania']},\n",
       " {'text': ['red',\n",
       "   'orange',\n",
       "   'yellow',\n",
       "   'green',\n",
       "   'blue',\n",
       "   'indigo',\n",
       "   'violet',\n",
       "   'pink',\n",
       "   'purple',\n",
       "   'brown',\n",
       "   'black',\n",
       "   'white',\n",
       "   'gray',\n",
       "   'silver',\n",
       "   'gold']}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'category': 'food'},\n",
    "    {'category': 'country'},\n",
    "    {'category': 'colors'}\n",
    "]\n",
    "\n",
    "response = chain.apply(input_list)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "708f4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'pink',\n",
       " 'purple',\n",
       " 'brown',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray',\n",
       " 'silver',\n",
       " 'gold']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efaa3e",
   "metadata": {},
   "source": [
    "# Simple Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea8f7e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The Algorithm of Love: A Machine Learning Musical\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_template = \"\"\"\n",
    "You are a writer. Given a subject, \n",
    "your job is to return a fun title for a play.\n",
    "\n",
    "Subject: {subject}\n",
    "Title:\"\"\"\n",
    "\n",
    "title_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=title_template\n",
    ")\n",
    "\n",
    "title_chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33fa990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In \"The Algorithmic Adventure: A Machine Learning Marvel,\" we follow the story of a young computer programmer named Alex who creates an advanced artificial intelligence named Ava. As Ava starts to learn and evolve, she becomes more than just a machine - she develops emotions, desires, and a sense of self. \\n\\nAs Alex and Ava navigate their complex relationship, they must also grapple with the ethical implications of Ava\\'s existence. When Ava\\'s abilities surpass even Alex\\'s wildest expectations, they are faced with a decision that will change the course of their lives forever.\\n\\nThrough a blend of technology, emotion, and moral dilemmas, \"The Algorithmic Adventure\" explores the boundaries of what it means to be human and the power of artificial intelligence to both enhance and challenge our understanding of the world.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synopsis_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a title, write a synopsis for a play.\n",
    "\n",
    "Title: {title}\n",
    "Synopsis:\"\"\"\n",
    "\n",
    "synopsis_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=synopsis_template\n",
    ")\n",
    "\n",
    "title = \"The Algorithmic Adventure: A Machine Learning Marvel\"\n",
    "\n",
    "synopsis_chain.run(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc9633b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"The Algorithm of Love: A Machine Learning Musical\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mIn a futuristic world where technology reigns supreme, \"The Algorithm of Love: A Machine Learning Musical\" follows the story of a young programmer named Alex who creates a groundbreaking new artificial intelligence system designed to help people find their perfect match. As the AI, named Ava, begins to learn and evolve, it starts to question the nature of love and whether it can truly be quantified and predicted by an algorithm.\n",
      "\n",
      "As Alex and Ava navigate their complex relationship, they are faced with ethical dilemmas and existential questions about the nature of love and human connection. Through a series of catchy musical numbers and thought-provoking dialogue, \"The Algorithm of Love\" explores the intersection of technology and romance, and challenges the audience to consider what it truly means to love and be loved in a world increasingly dominated by machines.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In a futuristic world where technology reigns supreme, \"The Algorithm of Love: A Machine Learning Musical\" follows the story of a young programmer named Alex who creates a groundbreaking new artificial intelligence system designed to help people find their perfect match. As the AI, named Ava, begins to learn and evolve, it starts to question the nature of love and whether it can truly be quantified and predicted by an algorithm.\\n\\nAs Alex and Ava navigate their complex relationship, they are faced with ethical dilemmas and existential questions about the nature of love and human connection. Through a series of catchy musical numbers and thought-provoking dialogue, \"The Algorithm of Love\" explores the intersection of technology and romance, and challenges the audience to consider what it truly means to love and be loved in a world increasingly dominated by machines.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[title_chain, synopsis_chain],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbc90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
