{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a7c8fd44",
      "metadata": {
        "id": "a7c8fd44"
      },
      "source": [
        "# Indexing data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kPWroRIfyNCl"
      },
      "id": "kPWroRIfyNCl"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain pypdf faiss-cpu openai tiktoken pinecone-client newsapi-python chromadb apify GitPython"
      ],
      "metadata": {
        "id": "AcxjiQ6g5hrm"
      },
      "id": "AcxjiQ6g5hrm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the pdf file and set file path"
      ],
      "metadata": {
        "id": "sCpkRzEiXcoD"
      },
      "id": "sCpkRzEiXcoD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e748d19",
      "metadata": {
        "id": "8e748d19"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "file_path = '/content/ESLII_print12_toc.pdf'\n",
        "\n",
        "loader = PyPDFLoader(file_path=file_path)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "data = loader.load_and_split(text_splitter=text_splitter)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4362f102",
      "metadata": {
        "id": "4362f102"
      },
      "outputs": [],
      "source": [
        "data[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide Openai Key"
      ],
      "metadata": {
        "id": "311Dz_oZXry3"
      },
      "id": "311Dz_oZXry3"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR API KEY'"
      ],
      "metadata": {
        "id": "dCKCywGR7btx"
      },
      "id": "dCKCywGR7btx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c582b114",
      "metadata": {
        "id": "c582b114"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(show_progress_bar=True)\n",
        "\n",
        "vector1 = embeddings.embed_query('How are you?')\n",
        "\n",
        "len(vector1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c3f9ca",
      "metadata": {
        "id": "22c3f9ca"
      },
      "outputs": [],
      "source": [
        "embeddings.__dict__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3d6e58",
      "metadata": {
        "id": "9e3d6e58"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    return np.dot(vec1,vec2)/(norm(vec1)*norm(vec2))\n",
        "\n",
        "vector1 = embeddings.embed_query('machine learning')\n",
        "vector2 = embeddings.embed_query('artificial intelligence')\n",
        "cosine = get_cosine(vector1, vector2)\n",
        "cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d15940a5",
      "metadata": {
        "id": "d15940a5"
      },
      "outputs": [],
      "source": [
        "vector3 = embeddings.embed_query('peperoni pizza')\n",
        "cosine = get_cosine(vector2, vector3)\n",
        "cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b142511",
      "metadata": {
        "id": "6b142511"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "index = FAISS.from_documents(data, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6fa1f42",
      "metadata": {
        "id": "c6fa1f42"
      },
      "outputs": [],
      "source": [
        "index.similarity_search_with_relevance_scores(\n",
        "    \"What is machine learning?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "972168c6",
      "metadata": {
        "scrolled": false,
        "id": "972168c6"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "retriever = index.as_retriever()\n",
        "retriever.search_kwargs['fetch_k'] = 20\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 10\n",
        "\n",
        "llm = ChatOpenAI()\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "chain.run(\n",
        "    'What is machine learning?',\n",
        "    callbacks=[handler]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b127210e",
      "metadata": {
        "id": "b127210e"
      },
      "source": [
        "# Loading data into a Vector Database"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to create pinecone api key and environment details"
      ],
      "metadata": {
        "id": "UewUNZyJhlcr"
      },
      "id": "UewUNZyJhlcr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an account in pinecone, then get API key and Create a new Index, give a name(index name) and Dimensions = 1536 then Metric = cosine"
      ],
      "metadata": {
        "id": "87_28dBQX3os"
      },
      "id": "87_28dBQX3os"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = 'API KEY'\n",
        "os.environ[\"PINECONE_ENV\"] = 'YOUR ENV'\n"
      ],
      "metadata": {
        "id": "660UPNv4AIiU"
      },
      "id": "660UPNv4AIiU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key=os.environ.get(\"API KEY\"))\n",
        "\n",
        "# Now do stuff\n",
        "if 'index name' not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name='index name',\n",
        "        dimension=1536,\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='google',\n",
        "            region='Iowa (us-central1)'\n",
        "        )\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "3mjiODuj_dfD"
      },
      "id": "3mjiODuj_dfD",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zXK6I8JOWIls"
      },
      "id": "zXK6I8JOWIls",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "index_name = \"index name\"\n",
        "db = Pinecone.from_documents(\n",
        "     data,\n",
        "    embeddings,\n",
        "    index_name=index_name\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eE5zjKUQuKhx"
      },
      "id": "eE5zjKUQuKhx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1edfee8",
      "metadata": {
        "id": "c1edfee8"
      },
      "outputs": [],
      "source": [
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=db.as_retriever(),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "chain.run(\n",
        "    'What is machine learning?',\n",
        "    callbacks=[handler]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07781599",
      "metadata": {
        "id": "07781599"
      },
      "source": [
        "# Providing sources"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an account in https://newsapi.org/ and get a API Key"
      ],
      "metadata": {
        "id": "rMZL07p2WMw0"
      },
      "id": "rMZL07p2WMw0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea95be00",
      "metadata": {
        "id": "ea95be00"
      },
      "outputs": [],
      "source": [
        "from datetime import date, timedelta\n",
        "from newsapi import NewsApiClient\n",
        "\n",
        "newsapi = NewsApiClient(api_key=\"NEWS API KEY\")\n",
        "\n",
        "today = date.today()\n",
        "last_week = today - timedelta(days=7)\n",
        "\n",
        "latest_news = newsapi.get_everything(\n",
        "    q='artificial intelligence',\n",
        "    from_param=last_week.strftime(\"%Y-%m-%d\"),\n",
        "    to=today.strftime(\"%Y-%m-%d\"),\n",
        "    sort_by='relevancy',\n",
        "    language='en'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f8e50d",
      "metadata": {
        "id": "e2f8e50d"
      },
      "outputs": [],
      "source": [
        "latest_news['articles']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e31adb",
      "metadata": {
        "id": "e4e31adb"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs = []\n",
        "for article in latest_news['articles']:\n",
        "    page_content = \"\"\n",
        "    if article['title']:\n",
        "        page_content += article['title'] + '\\n\\n'\n",
        "    if article['description']:\n",
        "        page_content += article['description']\n",
        "\n",
        "    docs.append(\n",
        "        Document(\n",
        "            page_content=page_content,\n",
        "            metadata={\n",
        "                'source': article['url'],\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "\n",
        "print(docs[0].page_content)\n",
        "print(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c399a97",
      "metadata": {
        "id": "9c399a97"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_qa_with_sources_chain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "qa_chain = create_qa_with_sources_chain(llm)\n",
        "\n",
        "doc_prompt = PromptTemplate(\n",
        "    template=\"Content: {page_content}\\nSource: {source}\",\n",
        "    input_variables=[\"page_content\", \"source\"],\n",
        ")\n",
        "\n",
        "final_qa_chain = StuffDocumentsChain(\n",
        "    llm_chain=qa_chain,\n",
        "    document_variable_name=\"context\",\n",
        "    document_prompt=doc_prompt,\n",
        ")\n",
        "\n",
        "index = FAISS.from_documents(docs, embedding=embeddings)\n",
        "\n",
        "\n",
        "chain = RetrievalQA(\n",
        "    retriever=index.as_retriever(),\n",
        "    combine_documents_chain=final_qa_chain\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753705b0",
      "metadata": {
        "id": "753705b0"
      },
      "outputs": [],
      "source": [
        "question = \"\"\"\n",
        "What is the most important news about artificial intelligence from last week?\n",
        "\"\"\"\n",
        "\n",
        "answer = chain.run(question)\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5605d77e",
      "metadata": {
        "id": "5605d77e"
      },
      "source": [
        "# Indexing a website"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['APIFY_API_TOKEN'] = 'YOUR APIFY TOKEN'"
      ],
      "metadata": {
        "id": "l09EJv41pBCN"
      },
      "id": "l09EJv41pBCN",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from langchain.utilities import ApifyWrapper\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "apify = ApifyWrapper()\n",
        "\n",
        "loader = apify.call_actor(\n",
        "    actor_id=\"apify/website-content-crawler\",\n",
        "    run_input={\n",
        "        \"startUrls\": [{\"url\": \"https://vingyani.com/\"}],\n",
        "        \"aggressivePrune\": True,\n",
        "    },\n",
        "    dataset_mapping_function=lambda item:Document  (\n",
        "        page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
        "    ),\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_W0ovNMppVc7"
      },
      "id": "_W0ovNMppVc7",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "index = VectorstoreIndexCreator(\n",
        "    text_splitter=text_splitter\n",
        ").from_loaders([loader])\n",
        "\n",
        "index"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "DaoliNxCoZMG"
      },
      "id": "DaoliNxCoZMG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2ffdbc",
      "metadata": {
        "id": "4d2ffdbc"
      },
      "outputs": [],
      "source": [
        "#query = \"What is the main subject of the aiedge newsletter?\"\n",
        "\n",
        "query = \"What is the main subject of the vingyani?\"\n",
        "\n",
        "index.query_with_sources(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641ec816",
      "metadata": {
        "id": "641ec816"
      },
      "outputs": [],
      "source": [
        "retriever = index.vectorstore.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        ")\n",
        "\n",
        "#query = \"What is the most recent article of the aiedge newsletter?\"\n",
        "\n",
        "query = \"What is the most recent article of the vingyani?\"\n",
        "\n",
        "qa.run(\n",
        "    query,\n",
        "    callbacks=[handler]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9576391",
      "metadata": {
        "id": "e9576391"
      },
      "source": [
        "# Indexing a GitHub repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a9efb4",
      "metadata": {
        "id": "36a9efb4"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import GitLoader\n",
        "\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./data/repo/\",\n",
        "    file_filter=lambda file_path: file_path.endswith(\".py\"),\n",
        "    branch=\"master\",\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea14a216",
      "metadata": {
        "id": "ea14a216"
      },
      "outputs": [],
      "source": [
        "print(documents[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32151b38",
      "metadata": {
        "id": "32151b38"
      },
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72caecb9",
      "metadata": {
        "id": "72caecb9"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import Language\n",
        "\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON,\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "documents = python_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60369f52",
      "metadata": {
        "id": "60369f52"
      },
      "outputs": [],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fce3759",
      "metadata": {
        "id": "1fce3759"
      },
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13363ebd",
      "metadata": {
        "id": "13363ebd"
      },
      "outputs": [],
      "source": [
        "index = FAISS.from_documents(documents, embeddings)\n",
        "retriever = index.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        ")\n",
        "\n",
        "query = \"What is a stuff chain?\"\n",
        "\n",
        "qa.run(query, callbacks=[handler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba54e42d",
      "metadata": {
        "scrolled": false,
        "id": "ba54e42d"
      },
      "outputs": [],
      "source": [
        "retriever.search_kwargs[\"distance_metric\"] = \"cos\"\n",
        "retriever.search_kwargs['fetch_k'] = 200\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 20\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        ")\n",
        "\n",
        "query = \"When should I use a map reduce chain?\"\n",
        "\n",
        "qa.run(query, callbacks=[handler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6aaf21a",
      "metadata": {
        "scrolled": false,
        "id": "f6aaf21a"
      },
      "outputs": [],
      "source": [
        "query = \"When should I use a map rank chain?\"\n",
        "\n",
        "qa.run(query, callbacks=[handler])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (langchain)",
      "language": "python",
      "name": "langchain"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}