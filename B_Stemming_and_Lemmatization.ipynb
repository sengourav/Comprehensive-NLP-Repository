{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42a2731",
   "metadata": {},
   "source": [
    "# Stemming with NLTK\n",
    "\n",
    "\n",
    "After stop words are removed from sentences, the next step in data preprocessing pertains to **stemming**. Stemming is the process of reducing words (or tokens) to their root form by removing things like suffixes, prefixes, or other word affixes. This reduction of a word to its stem allows for easier comparison of words and their respective meanings.\n",
    "\n",
    "There are several stemming techniques, in this notebook we're leveraging `NLTK`'s `PorterStemmer()`. Read more about the details [here](https://www.nltk.org/api/nltk.stem.porter.html?highlight=porter+stemmer#nltk.stem.porter.PorterStemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28ae09",
   "metadata": {},
   "source": [
    "![stemming](images/stemming.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c60bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7f92b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\gorav\n",
      "[nltk_data]     sen\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ea65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\gorav\n",
      "[nltk_data]     sen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gorav sen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90a6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate porter stemmer\n",
    "\n",
    "port_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d69ac811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'run: run'\n",
      "'running: run'\n",
      "'runs: run'\n",
      "'runner: runner'\n",
      "'runners: runner'\n"
     ]
    }
   ],
   "source": [
    "# Stemming similar words \n",
    "\n",
    "words = [\"run\", \"running\", \"runs\", \"runner\", \"runners\"]\n",
    "\n",
    "for w in words:\n",
    "    pprint.pprint(f\"{w}: {port_stemmer.stem(w)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06560edc",
   "metadata": {},
   "source": [
    "## Tokenizing and Stemming Multiple Sentences \n",
    "\n",
    "Building on the simple example above, let's take a look stemming a longer corpus. In order to apply the `PorterStemmer()`, the corpus will first need to be tokenized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee56263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Boston: boston'\n",
      "'Marathon: marathon'\n",
      "'runners: runner'\n",
      "'run: run'\n",
      "'the: the'\n",
      "'race: race'\n",
      "'by: by'\n",
      "'running: run'\n",
      "'26.2: 26.2'\n",
      "'miles: mile'\n",
      "'.: .'\n"
     ]
    }
   ],
   "source": [
    "# Stemming several sentences \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "corpus = \"Boston Marathon runners run the race by running 26.2 miles.\"\n",
    "\n",
    "# Tokenize first \n",
    "words = word_tokenize(corpus)\n",
    "\n",
    "# Apply the stemmer \n",
    "for w in words:\n",
    "    pprint.pprint(f\"{w}: {port_stemmer.stem(w)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6256",
   "metadata": {},
   "source": [
    "# Lemmatization with NLTK\n",
    "\n",
    "Somewhat related to stemming is **lemmatization** which is the process that groups together different inflected forms of a word so they can be analyzed as a single item. For example, in the lemmatization step the words “run”, “ran”, and “running” would all be converted into the base form, “run.”\n",
    "\n",
    "Similar to stemming, there are several techniques for lemmatization. In this example, we'll us the `WordNetLemmatizer()` from `NLTK`. Since lemmatization depends on the part of speech, the `WordNetLemmatizer()` accepts a `pos` argument to denote the part of speech. Read more about the `WordNetLemmatizer` [here](https://www.nltk.org/api/nltk.stem.wordnet.html?highlight=lemmatizer#nltk.stem.wordnet.WordNetLemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3561c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:  run\n",
      "running:  run\n",
      "better:  good\n",
      "better:  better\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "word_net_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Single word examples of lemmatizing \n",
    "print(\"runs: \", word_net_lemmatizer.lemmatize(\"runs\", pos=\"v\"))\n",
    "print(\"running: \", word_net_lemmatizer.lemmatize(\"running\", pos=\"v\"))\n",
    "\n",
    "# Note that the part of speech matters for lemmatizing \n",
    "print(f\"better: \", word_net_lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(f\"better: \", word_net_lemmatizer.lemmatize(\"better\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c33896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs:  run\n",
      "running:  run\n",
      "better:  good\n",
      "better:  better\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "word_net_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Single word examples of lemmatizing \n",
    "print(\"runs: \", word_net_lemmatizer.lemmatize(\"runs\", pos=\"v\"))\n",
    "print(\"running: \", word_net_lemmatizer.lemmatize(\"running\", pos=\"v\"))\n",
    "\n",
    "# Note that the part of speech matters for lemmatizing \n",
    "print(f\"better: \", word_net_lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(f\"better: \", word_net_lemmatizer.lemmatize(\"better\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f4ddb7",
   "metadata": {},
   "source": [
    "### Tokenizing and Lemmatizing Sentences \n",
    "\n",
    "Advancing from the example above, let's look at when lemmatization looks like for sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f880cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston: Boston\n",
      "Marathon: Marathon\n",
      "runners: runner\n",
      "run: run\n",
      "the: the\n",
      "race: race\n",
      "by: by\n",
      "running: running\n",
      "26.2: 26.2\n",
      "miles: mile\n",
      ".: .\n"
     ]
    }
   ],
   "source": [
    "# Tokenize corpus first \n",
    "\n",
    "words = word_tokenize(corpus)\n",
    "\n",
    "# lemmatize tokens \n",
    "for w in words:\n",
    "    print(f\"{w}: {word_net_lemmatizer.lemmatize(w)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e3f03",
   "metadata": {},
   "source": [
    "This result isn't quite as expected - since `run` and `running` are similar, we'd expect them to be reduced to the same base. **Part of speech tagging** can be used to pass the accompanying part of speech to the `WordNetLemmatizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31d3d8",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging\n",
    "\n",
    "In addition to stemming and lemmatization, preprocessing can also include part of speech tagging. Part of speech tagging (POS tagging) involves assigning a part of speech to each word in a sentence based on context. This tagging can be useful for mapping the context and relationship of different words numerically. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28abb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Boston', 'NNP'),\n",
       " ('Marathon', 'NNP'),\n",
       " ('runners', 'NNS'),\n",
       " ('run', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('race', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('running', 'VBG'),\n",
       " ('26.2', 'CD'),\n",
       " ('miles', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eb2f6",
   "metadata": {},
   "source": [
    "Since the POS tags are slightly different than what the `Lemmatizer` expects, we'll need to create a function that maps to the `WordNet` POS tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a91f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def pos_tagger(tag: str):\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    if tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282bb387",
   "metadata": {},
   "source": [
    "Let's re-write the lemmatizer loop with the part of speech tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ea1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Boston', 'n'), ('Marathon', 'n'), ('runners', 'n'), ('run', 'v'), ('the', None), ('race', 'n'), ('by', None), ('running', 'v'), ('26.2', None), ('miles', 'n'), ('.', None)]\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(words)\n",
    "\n",
    "retagged = []\n",
    "for i in range(0, len(tagged)):\n",
    "    old_list = list(tagged[i])\n",
    "    new_tag = pos_tagger(old_list[1])\n",
    "    append_value = (old_list[0], new_tag)\n",
    "    retagged.append(append_value)\n",
    "    \n",
    "print(retagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f349da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_sentence = []\n",
    "\n",
    "for word, tag in retagged:\n",
    "    if tag is None:\n",
    "        lemmatized_sentence.append(word)\n",
    "    else:\n",
    "        lemmatized_sentence.append(word_net_lemmatizer.lemmatize(word, pos=tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29b88ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boston',\n",
      " 'Marathon',\n",
      " 'runner',\n",
      " 'run',\n",
      " 'the',\n",
      " 'race',\n",
      " 'by',\n",
      " 'run',\n",
      " '26.2',\n",
      " 'mile',\n",
      " '.']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c46a38",
   "metadata": {},
   "source": [
    "That looks better! After part of speech tagging, we can see that `run` and `running` have been properly lemmatized. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
